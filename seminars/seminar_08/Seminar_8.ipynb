{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wo4efBW3jGPv"
      },
      "source": [
        "<center>\n",
        "    \n",
        "# [Компьютерное зрение](https://cogmodel.mipt.ru/wiki/index.php/%D0%9A%D0%BE%D0%BC%D0%BF%D1%8C%D1%8E%D1%82%D0%B5%D1%80%D0%BD%D0%BE%D0%B5_%D0%B7%D1%80%D0%B5%D0%BD%D0%B8%D0%B5)\n",
        "\n",
        "## <center> Семинар 8 - Методы построения оптического потока по последовательности изображений\n",
        "\n",
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uHyFe6rNjGP8"
      },
      "source": [
        "Источник - https://habr.com/ru/post/201406/\n",
        "\n",
        "$\\textbf{Task statement}$: Оптический поток (ОП) – изображение видимого движения, представляющее собой сдвиг каждой точки (пикселя) между двумя изображениями.\n",
        "\n",
        "По сути, он представляет собой поле скоростей. Суть ОП в том, что для каждой точки изображения $I_{t_0} (\\vec{r})$ находится такой вектор сдвига $\\delta \\vec{r}$, чтобы было соответсвие между исходной точкой и точкой на следущем фрейме $I_{t_1} (\\vec{r} + \\delta \\vec{r})$. В качестве метрики соответвия берут близость интенсивности пикселей, беря во внимание маленькую разницу по времени между кадрами: $\\delta{t} = t_{1} - t_{0}$. В более точных методах точку можно привязывать к объекту на основе, например, выделения ключевых точек, а также считать градиенты вокруг точки, лапласианы и проч.\n",
        "\n",
        "$\\textbf{For what}$: Определение собственной скорости, Определение локализации, Улучшение методов трекинга объектов, сегментации, Детектирование событий, Сжатие видеопотока и проч.\n",
        "\n",
        "![](https://github.com/alexmelekhin/cv_course_2023/blob/main/seminars/seminar_08/data/tennis.png?raw=1)\n",
        "\n",
        "Разделяют 2 вида оптического потока - плотный (dense) [Farneback method, neural nets], работающий с целым изображением, и выборочный (sparse) [Lucas-Kanade method], работающий с ключевыми точками"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "tags": [],
        "id": "S8Ssx5MNjGQE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d7d1fb9-ba07-42aa-ff71-632a209f6710"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-04-05 19:36:16--  https://www.bogotobogo.com/python/OpenCV_Python/images/mean_shift_tracking/slow_traffic_small.mp4\n",
            "Resolving www.bogotobogo.com (www.bogotobogo.com)... 173.254.30.214\n",
            "Connecting to www.bogotobogo.com (www.bogotobogo.com)|173.254.30.214|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2018126 (1.9M) [video/mp4]\n",
            "Saving to: ‘data/slow_traffic_small.mp4’\n",
            "\n",
            "data/slow_traffic_s 100%[===================>]   1.92M  2.10MB/s    in 0.9s    \n",
            "\n",
            "2023-04-05 19:36:18 (2.10 MB/s) - ‘data/slow_traffic_small.mp4’ saved [2018126/2018126]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!mkdir data\n",
        "!wget https://www.bogotobogo.com/python/OpenCV_Python/images/mean_shift_tracking/slow_traffic_small.mp4 -O data/slow_traffic_small.mp4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BNFPyVDYjGQL"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import IPython\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o5zOtae5jGQN"
      },
      "source": [
        "## Lucas-Kanade (sparse)\n",
        "\n",
        "Пусть $I_{1} = I(x, y, t_{1})$ интенсивность в некоторой точке (x, y) на первом изображении (т. е. в момент времени t). На втором изображении эта точка сдвинулась на (dx, dy), при этом прошло время dt, тогда $I_{2} = I(x + dx, y + dx, t_{1} + dt) \\approx I_{1} + I_{x}dx + I_{y}dy +  I_{t}dt$. Из постановки задачи следует, что интенсивность пикселя не изменилась, тогда $I_{1} = I_{2}$. Далее определяем $dx, dy$.\n",
        "\n",
        "Самое простое решение проблемы – алгоритм Лукаса-Канаде. У нас же на изображении объекты размером больше 1 пикселя, значит, скорее всего, в окрестности текущей точки у других точек будут примерно такие же сдвиги. Поэтому мы возьмем окно вокруг этой точки и минимизируем (по МНК) в нем суммарную погрешность с весовыми коэффициентами, распределенными по Гауссу, то есть так, чтобы наибольший вес имели пиксели, ближе всего находящиеся к исследуемому.\n",
        "\n",
        "**Полезные материалы:** \n",
        "- цикл видео-лекций от First Principles of Computer Vision, посвященный Optical Flow и алгоритму Lucas-Kanade: https://youtube.com/playlist?list=PL2zRqk16wsdoYzrWStffqBAoUY8XdvatV"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5SkhZX3cjGQP"
      },
      "source": [
        "### Вопрос 1\n",
        "\n",
        "В `cv2.calcOpticalFlowPyrLK` есть параметр, отвечающий за ImagePiramid. Зачем нужна пирамида изображений в случае вычисления оптического потока?\n",
        "\n",
        "**Ответ:** гауссова пирамида изображений позволяет рассмотреть вопрос формирования оптического потока на разных масштабах, например, в формате различия движения объектов разного размера, на разных планах (переднем/заднем), что позволяет фиксировать всевозможные объекты на изображении."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tNB9RyAmjGQQ"
      },
      "source": [
        "### Задание 1\n",
        "\n",
        "Напишите реализацию Лукаса-Канаде c помощью numpy и cv2. Сравните с реализацией `cv2.calcOpticalFlowPyrLK`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4uqz6pywjGQR"
      },
      "outputs": [],
      "source": [
        "def get_derivatives(\n",
        "    img1,\n",
        "    img2\n",
        ") -> list:\n",
        "    \n",
        "    kernel_x = np.array([[-1, 1], [-1, 1]])\n",
        "    kernel_y = np.array([[-1, -1], [1, 1]])\n",
        "    kernel_t = np.array([[1, 1], [1, 1]])\n",
        "\n",
        "    dx = cv2.filter2D(img1, -1, kernel_x)\n",
        "    dy = cv2.filter2D(img1, -1, kernel_y)\n",
        "    dt = cv2.filter2D(img2, -1, kernel_t) + cv2.filter2D(img1, -1, -kernel_t) \n",
        "    return dx, dy, dt\n",
        "\n",
        "# arguments like in cv2 lib\n",
        "def my_calcOpticalFlowPyrLK(\n",
        "    prevImg,\n",
        "    nextImg,\n",
        "    prevPts,\n",
        "    nextPts, #None is our case\n",
        "    winSize,\n",
        "    # maxLevel, #if you want to be an expert in CV,\n",
        "    #uncomment it and apply in LK method :)\n",
        ") -> np.array:\n",
        "    '''\n",
        "    You should return output vector of 2D points\n",
        "    (with single-precision floating-point coordinates)\n",
        "    containing the calculated new positions of input features in the second image\n",
        "    ''' \n",
        "    # prevImg = prevImg/255.\n",
        "    # nextImg = nextImg/255.\n",
        "\n",
        "    dx, dy, dt = get_derivatives(prevImg, nextImg)\n",
        "    nextPts = []\n",
        "    w = (winSize[0]//2, winSize[1]//2)\n",
        "    for keypoint in prevPts:\n",
        "        keypoint = keypoint.ravel()\n",
        "        i, j = [int(_) for _ in keypoint[::-1]]\n",
        "        \n",
        "        Ix = dx[i-w[0]:i+w[0]+1, j-w[1]:j+w[1]+1].flatten()\n",
        "        Iy = dy[i-w[0]:i+w[0]+1, j-w[1]:j+w[1]+1].flatten()\n",
        "        It = dt[i-w[0]:i+w[0]+1, j-w[1]:j+w[1]+1].flatten()\n",
        "\n",
        "        b = It.reshape(-1, 1)\n",
        "        A = np.vstack((Ix, Iy)).T\n",
        "        # solution = np.matmul(np.matmul(np.linalg.pinv(np.matmul(A.T, A)), A.T), b).ravel()\n",
        "        \n",
        "        # iterative solution works fine\n",
        "        solution = np.linalg.lstsq(A, b, rcond=1e-3)[0].ravel()\n",
        "        # find result coordinates\n",
        "        if solution.all():\n",
        "            nextPts.append([keypoint + solution])\n",
        "\n",
        "    return np.expand_dims(np.stack(nextPts), axis=1) if len(nextPts) else None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VRD96W4njGQT"
      },
      "source": [
        "### Релизация OpenCV - cv2.calcOpticalFlowPyrLK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z8VMSQ--jGQU",
        "outputId": "539ddeaa-a4c8-4e41-a78c-7b80ca31e74f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████▉| 913/914 [00:04<00:00, 203.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No frames grabbed!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "video_path = 'data/slow_traffic_small.mp4'\n",
        "\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "fps    = cap.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
        "out = cv2.VideoWriter('output_LKmine.mp4', fourcc, fps, (width, height))\n",
        "\n",
        "# params for ShiTomasi corner detection\n",
        "feature_params = dict(\n",
        "    maxCorners = 200,\n",
        "    qualityLevel = 0.3,\n",
        "    minDistance = 7,\n",
        "    blockSize = 7,\n",
        ")\n",
        "\n",
        "# Parameters for lucas kanade optical flow\n",
        "lk_params = dict(\n",
        "    #window size\n",
        "    winSize  = (30, 30),\n",
        "    #image piramid\n",
        "    # maxLevel = 2,\n",
        ")\n",
        "# Create some random colors\n",
        "color = np.random.randint(0, 255, (100, 3))\n",
        "# Take first frame and find corners in it\n",
        "ret, old_frame = cap.read()\n",
        "old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY) \n",
        "p0 = cv2.goodFeaturesToTrack(old_gray, mask = None, **feature_params)\n",
        "# Create a mask image for drawing purposes\n",
        "mask = np.zeros_like(old_frame)\n",
        "for i in tqdm(range(length)):\n",
        "    \n",
        "    ret, frame = cap.read()\n",
        "    \n",
        "    if not ret:\n",
        "        print('No frames grabbed!')\n",
        "        break\n",
        "        \n",
        "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "    # calculate optical flow\n",
        "    # see params here https://docs.opencv.org/3.4/dc/d6b/group__video__track.html#ga473e4b886d0bcc6b65831eb88ed93323\n",
        "    p1 = my_calcOpticalFlowPyrLK(\n",
        "        prevImg=old_gray,\n",
        "        nextImg=frame_gray,\n",
        "        prevPts=p0,\n",
        "        nextPts=None,\n",
        "        **lk_params,\n",
        "    )\n",
        "    # Select good points where status is equal 1\n",
        "    good_old = p0\n",
        "    if p1 is None: \n",
        "        good_new = p0\n",
        "    else:\n",
        "        good_new = p1\n",
        "    \n",
        "    # draw the tracks\n",
        "    for i, (new, old) in enumerate(zip(good_new, good_old)):\n",
        "        a, b = new.ravel()\n",
        "        c, d = old.ravel()\n",
        "        mask = cv2.line(mask, (int(a), int(b)), (int(c), int(d)), color[i].tolist(), 2)\n",
        "        frame = cv2.circle(frame, (int(a), int(b)), 5, color[i].tolist(), -1)\n",
        "        \n",
        "    img = cv2.add(frame, mask)\n",
        "    # Now update the previous frame and previous points\n",
        "    old_gray = frame_gray.copy()\n",
        "    p0 = good_new.reshape(-1, 1, 2)\n",
        "    \n",
        "    out.write(img)\n",
        "    \n",
        "cap.release()\n",
        "out.release()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "video_path = 'data/slow_traffic_small.mp4'\n",
        "\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "fps    = cap.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
        "out = cv2.VideoWriter('output_LKcv2fixed.mp4', fourcc, fps, (width, height))\n",
        "\n",
        "# params for ShiTomasi corner detection\n",
        "feature_params = dict(\n",
        "    maxCorners = 100,\n",
        "    qualityLevel = 0.3,\n",
        "    minDistance = 7,\n",
        "    blockSize = 7,\n",
        ")\n",
        "\n",
        "# Parameters for lucas kanade optical flow\n",
        "lk_params = dict(\n",
        "    #window size\n",
        "    winSize  = (15, 15),\n",
        "    #image piramid\n",
        "    maxLevel = 2,\n",
        "    # after the specified maximum number of iterations criteria.maxCount\n",
        "    #or when the search window moves by less than criteria.epsilon.\n",
        "    criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03),\n",
        ")\n",
        "# Create some random colors\n",
        "color = np.random.randint(0, 255, (100, 3))\n",
        "# Take first frame and find corners in it\n",
        "ret, old_frame = cap.read()\n",
        "old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)\n",
        "def track_kp(img):\n",
        "    return cv2.goodFeaturesToTrack(img, mask = None, **feature_params)\n",
        "p0 = track_kp(old_gray)\n",
        "# Create a mask image for drawing purposes\n",
        "mask = np.zeros_like(old_frame)\n",
        "for i in tqdm(range(length)):\n",
        "    \n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        print('No frames grabbed!')\n",
        "        break\n",
        "        \n",
        "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "    \n",
        "    # calculate optical flow\n",
        "    # see params here https://docs.opencv.org/3.4/dc/d6b/group__video__track.html#ga473e4b886d0bcc6b65831eb88ed93323\n",
        "    p1, st, err = cv2.calcOpticalFlowPyrLK(\n",
        "        prevImg=old_gray,\n",
        "        nextImg=frame_gray,\n",
        "        prevPts=p0,\n",
        "        nextPts=None,\n",
        "        **lk_params,\n",
        "    )\n",
        "    # Select good points where status is equal 1\n",
        "    if p1 is not None:\n",
        "        good_new = p1[st==1]\n",
        "        good_old = p0[st==1]\n",
        "    # draw the tracks\n",
        "    for i, (new, old) in enumerate(zip(good_new, good_old)):\n",
        "        a, b = new.ravel()\n",
        "        c, d = old.ravel()\n",
        "        mask = cv2.line(mask, (int(a), int(b)), (int(c), int(d)), color[i].tolist(), 2)\n",
        "        frame = cv2.circle(frame, (int(a), int(b)), 5, color[i].tolist(), -1)\n",
        "        \n",
        "    img = cv2.add(frame, mask)\n",
        "    # Now update the previous frame and previous points\n",
        "    old_gray = frame_gray.copy()\n",
        "    \n",
        "    p0 = good_new.reshape(-1, 1, 2)\n",
        "\n",
        "    #fixing the flow\n",
        "    # if np.array([(p > old_frame.shape).all() for p in p0.ravel()]).any():\n",
        "    #     p0 = track_kp(old_gray)\n",
        "\n",
        "    out.write(img)\n",
        "    \n",
        "cap.release()\n",
        "out.release()"
      ],
      "metadata": {
        "id": "M_eX4wE40JVV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ca43c0c-5b58-46d1-a9e1-0f2fea18c02f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████▉| 913/914 [00:03<00:00, 272.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No frames grabbed!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-rFwPyBjGQd"
      },
      "source": [
        "### Вопрос 2\n",
        "\n",
        "Какие проблемы в текущей реализации вы увидели при просмотре результирующего видео? Как их можно устранить?\n",
        "\n",
        "**Ответ:** одна из очевидных проблем – ключевые точки фиксируются только в начале видео, на первом кадре, что строит не полный поток. Я исправил эту проблему небольшим \"костылём\": как только поток одной из ключевых точек \"покидает\" изображение, алгоритм редетектирует точки и запускает поток, получается гораздо лучше. \n",
        "```Python\n",
        "if np.array([(p > old_frame.shape).all() for p in p0.ravel()]).any():\n",
        "    p0 = track_kp(old_gray)\n",
        "```\n",
        "Можно сделать и элегантнее, но так тоже работает."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1cFBQ2qCjGQf"
      },
      "source": [
        "### Задание 2\n",
        "\n",
        "Напишите код, устраняющий одну из проблем, покажите результат до/после.\n",
        "\n",
        "Before: `/data/output_LKcv2.mp4` \\\\\n",
        "After: `/data/output_LKcv2fixed.mp4`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJFT71sBjGQg"
      },
      "source": [
        "## Farneback (dense)\n",
        "\n",
        "Метод Farneback носит несколько более глобальный характер, чем метод Лукаса-Канаде. Он опирается на предположение о том, что на всем изображении оптический поток будет достаточно гладким."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TRskWWMdjGQh",
        "outputId": "e15aaeaf-dc54-4db4-b4d8-5db61181b57c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  7%|▋         | 67/914 [00:06<01:18, 10.79it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-e83a7b2f9869>\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;31m#see arguments here https://docs.opencv.org/3.4/dc/d6b/group__video__track.html#ga5d10ebbd59fe09c5f650289ec0ece5af\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mflow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalcOpticalFlowFarneback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprvs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0mmag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mang\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcartToPolar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mhsv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mang\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m180\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "fps    = cap.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
        "out = cv2.VideoWriter('output_Farneback.mp4', fourcc, fps, (width, height))\n",
        "\n",
        "ret, frame1 = cap.read()\n",
        "prvs = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
        "hsv = np.zeros_like(frame1)\n",
        "hsv[..., 1] = 255\n",
        "\n",
        "for i in tqdm(range(length)):\n",
        "    \n",
        "    ret, frame2 = cap.read()\n",
        "    \n",
        "    if not ret:\n",
        "        print('No frames grabbed!')\n",
        "        break\n",
        "        \n",
        "    next = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
        "    \n",
        "    #see arguments here https://docs.opencv.org/3.4/dc/d6b/group__video__track.html#ga5d10ebbd59fe09c5f650289ec0ece5af\n",
        "    flow = cv2.calcOpticalFlowFarneback(prvs, next, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
        "    mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
        "    hsv[..., 0] = ang*180/np.pi/2\n",
        "    hsv[..., 2] = cv2.normalize(mag, None, 0, 255, cv2.NORM_MINMAX)\n",
        "    bgr = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
        "    prvs = next\n",
        "    \n",
        "    out.write(bgr)\n",
        "    \n",
        "cap.release()\n",
        "out.release()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ikr1U60yjGQj"
      },
      "source": [
        "Посмотрим, что получилось"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ATb-1gJtjGQk",
        "outputId": "e315e542-9378-4d7a-96da-af435c5a4844",
        "colab": {
          "resources": {
            "http://localhost:8080/output_Farneback.mp4": {
              "data": "CjwhRE9DVFlQRSBodG1sPgo8aHRtbCBsYW5nPWVuPgogIDxtZXRhIGNoYXJzZXQ9dXRmLTg+CiAgPG1ldGEgbmFtZT12aWV3cG9ydCBjb250ZW50PSJpbml0aWFsLXNjYWxlPTEsIG1pbmltdW0tc2NhbGU9MSwgd2lkdGg9ZGV2aWNlLXdpZHRoIj4KICA8dGl0bGU+RXJyb3IgNDA0IChOb3QgRm91bmQpISExPC90aXRsZT4KICA8c3R5bGU+CiAgICAqe21hcmdpbjowO3BhZGRpbmc6MH1odG1sLGNvZGV7Zm9udDoxNXB4LzIycHggYXJpYWwsc2Fucy1zZXJpZn1odG1se2JhY2tncm91bmQ6I2ZmZjtjb2xvcjojMjIyO3BhZGRpbmc6MTVweH1ib2R5e21hcmdpbjo3JSBhdXRvIDA7bWF4LXdpZHRoOjM5MHB4O21pbi1oZWlnaHQ6MTgwcHg7cGFkZGluZzozMHB4IDAgMTVweH0qID4gYm9keXtiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9lcnJvcnMvcm9ib3QucG5nKSAxMDAlIDVweCBuby1yZXBlYXQ7cGFkZGluZy1yaWdodDoyMDVweH1we21hcmdpbjoxMXB4IDAgMjJweDtvdmVyZmxvdzpoaWRkZW59aW5ze2NvbG9yOiM3Nzc7dGV4dC1kZWNvcmF0aW9uOm5vbmV9YSBpbWd7Ym9yZGVyOjB9QG1lZGlhIHNjcmVlbiBhbmQgKG1heC13aWR0aDo3NzJweCl7Ym9keXtiYWNrZ3JvdW5kOm5vbmU7bWFyZ2luLXRvcDowO21heC13aWR0aDpub25lO3BhZGRpbmctcmlnaHQ6MH19I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LnBuZykgbm8tcmVwZWF0O21hcmdpbi1sZWZ0Oi01cHh9QG1lZGlhIG9ubHkgc2NyZWVuIGFuZCAobWluLXJlc29sdXRpb246MTkyZHBpKXsjbG9nb3tiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSBuby1yZXBlYXQgMCUgMCUvMTAwJSAxMDAlOy1tb3otYm9yZGVyLWltYWdlOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSAwfX1AbWVkaWEgb25seSBzY3JlZW4gYW5kICgtd2Via2l0LW1pbi1kZXZpY2UtcGl4ZWwtcmF0aW86Mil7I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LTJ4LnBuZykgbm8tcmVwZWF0Oy13ZWJraXQtYmFja2dyb3VuZC1zaXplOjEwMCUgMTAwJX19I2xvZ297ZGlzcGxheTppbmxpbmUtYmxvY2s7aGVpZ2h0OjU0cHg7d2lkdGg6MTUwcHh9CiAgPC9zdHlsZT4KICA8YSBocmVmPS8vd3d3Lmdvb2dsZS5jb20vPjxzcGFuIGlkPWxvZ28gYXJpYS1sYWJlbD1Hb29nbGU+PC9zcGFuPjwvYT4KICA8cD48Yj40MDQuPC9iPiA8aW5zPlRoYXTigJlzIGFuIGVycm9yLjwvaW5zPgogIDxwPiAgPGlucz5UaGF04oCZcyBhbGwgd2Uga25vdy48L2lucz4K",
              "ok": false,
              "headers": [
                [
                  "content-length",
                  "1449"
                ],
                [
                  "content-type",
                  "text/html; charset=utf-8"
                ]
              ],
              "status": 404,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 171
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Video object>"
            ],
            "text/html": [
              "<video src=\"output_Farneback.mp4\" controls  >\n",
              "      Your browser does not support the <code>video</code> element.\n",
              "    </video>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "IPython.display.Video('output_Farneback.mp4')"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ICZlLkQQjt4U"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.16"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "5SkhZX3cjGQP",
        "v-rFwPyBjGQd",
        "1cFBQ2qCjGQf",
        "CJFT71sBjGQg"
      ]
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}